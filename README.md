# ğŸ‘¤ LARAIB AHMAD SIDDIQUI
**ğŸ¤– AI Trainer | ğŸ§­ Agent Evaluation Specialist (RLHF & Multimodal Systems)**  
ğŸ“ New Delhi, India  
ğŸ“§ laraibdevops@gmail.com | ğŸ“ +91-9540880891  

---

## ğŸ§  PROFESSIONAL SUMMARY

AI Trainer and Agent Evaluation Specialist with 3+ years of hands-on experience delivering high-fidelity evaluation, preference ranking, and alignment data for large-scale language models and multimodal AI systems. Direct contributor to production AI pipelines for enterprise and frontier-model deployments via multiple confidential AI research vendors and data-labeling platforms.

Expertise across **ğŸ” Reinforcement Learning from Human Feedback (RLHF)**, **ğŸ† reward-model training**, **ğŸ§­ tool-using agent (TAU) evaluation**, **ğŸ’¬ multi-turn reasoning alignment**, **ğŸ’» coding agent validation**, and **ğŸ‘ï¸ computer-vision QA**. Known for identifying **âŒ hallucinations**, **ğŸ“œ policy violations**, **ğŸ§  reasoning breakdowns**, and **ğŸ› ï¸ tool-misuse failures** that evade automated metrics.

---

## ğŸ§© CORE SKILLS

- ğŸ” Reinforcement Learning from Human Feedback (RLHF)
- ğŸ† Preference Ranking & Reward-Model Evaluation
- ğŸ§­ Tool-Using Agents (TAU) & Trajectory Analysis
- ğŸ’¬ Multi-Turn Conversation Evaluation
- ğŸ’» Coding Agent & Repo-Based Validation
- âŒ Hallucination Detection & Factuality QA
- ğŸ“œ Policy-Constrained Agent Evaluation
- ğŸ§  Multimodal Evaluation (Text, Image, Audio, Video)
- ğŸ‘ï¸ Computer Vision Annotation & QA
- ğŸ“ Schema-Driven Annotation & Golden-Set Validation

---

## ğŸ¢ PROFESSIONAL EXPERIENCE

### ğŸ”’ Confidential AI Research Vendor (via Global AI Services Firm)  
**AI Trainer â€“ LLM, Agent & Vision Evaluation** | 2023 â€“ Present

Delivered evaluation and alignment data across **ğŸ¤– LLM**, **ğŸ§­ agentic**, **ğŸ’» coding**, and **ğŸ‘ï¸ multimodal vision** pipelines used in production systems for enterprise-scale AI deployments.

**Key Contributions & Impact**

- **ğŸ” RLHF (3H Framework: Helpful, Honest, Harmless)**
  - Evaluated outputs for factual accuracy, safety, and intent alignment  
  - Authored structured preference rationales for reward-model training  
  - ğŸ“‰ Impact: Reduced hallucination frequency by ~40%

- **ğŸ’» Coding & ğŸ’¬ Multi-Turn Reasoning Evaluation**
  - Executed and debugged AI-generated code for runtime correctness  
  - Audited multi-turn reasoning drift and instruction-following failures  
  - ğŸ“ˆ Impact: Improved code reliability by ~35%

- **ğŸ—ï¸ Enterprise Coding Benchmarking (RFI / RFP Style)**
  - Assessed architecture quality, scalability, maintainability, and security  
  - Compared candidate outputs for production readiness  
  - â±ï¸ Impact: Reduced enterprise decision cycles by ~25%

- **ğŸ‘ï¸ Computer Vision QA (Pose Estimation & Video)**
  - Verified bounding boxes, keypoints, occlusions, and temporal tubelets  
  - Ensured â‰¥32-frame continuity and strict schema compliance  
  - ğŸ¯ Impact: Increased dataset precision by ~30%

- **ğŸ–¼ï¸ Vision Generation QA**
  - Evaluated identity preservation, anatomical correctness, and artifacts  
  - Applied strict pass/fail and failure taxonomy standards  
  - ğŸš€ Impact: Improved vision dataset filtering accuracy by ~25%

---

### ğŸ§ª Confidential AI Training Platform  
**AI Trainer â€“ RLHF & Multimodal Evaluation** | 2024 â€“ Present

- ğŸ§® Evaluated step-by-step mathematical and logical reasoning chains  
- âœï¸ Authored and QAâ€™d short-answer factual prompts  
- ğŸ”Š Performed audioâ€“text semantic alignment evaluation  
- âš–ï¸ Conducted pairwise side-by-side comparisons with code execution  

**Impact**
- ğŸ“ˆ Reasoning accuracy improved by ~40%  
- ğŸ§© Dataset quality improved by ~30%  
- ğŸ”— Multimodal consistency improved by ~25%

---

### ğŸ§­ Confidential Agent Evaluation Platform  
**AI Trainer â€“ Agent & Reward-Model Evaluation** | 2024

- Reviewed ğŸ› ï¸ tool-call sequences and agent state transitions (TAU framework)  
- Distinguished ğŸ¯ outcome correctness vs âš™ï¸ process correctness  
- Classified failures across Agent / User / System dimensions  
- Evaluated ğŸ“œ policy-restricted domains (authentication, payments, refunds)  
- Designed ğŸ’» repo-based coding agent evaluation tasks  

**Impact**
- ğŸ“Š Improved agent benchmarking fidelity  
- ğŸ” Reduced silent policy violations in tool-using agents

---

### ğŸ¥ Confidential Vision Annotation Vendor  
**AI Data Annotator â€“ Computer Vision** | 2024 â€“ Present

- Annotated ğŸ–¼ï¸ image and ğŸï¸ video datasets under strict schemas  
- Performed frame-level labeling and QA for production CV datasets  

---

## ğŸ“Š AGGREGATE IMPACT

- âŒ Hallucinations reduced by up to **40%**  
- ğŸ§  Reasoning accuracy improved by **~40%**  
- ğŸ’» Code correctness improved by **~35%**  
- ğŸ‘ï¸ Vision dataset precision improved by **25â€“30%**  
- ğŸš€ Delivered production-grade datasets for enterprise-scale AI systems  

---

## ğŸ¯ ROLE ALIGNMENT

Well suited for roles involving:

- ğŸ¤– LLM & Agent Evaluation  
- ğŸ” RLHF & Reward-Model Training  
- ğŸ§­ Tool-Using Agent Reliability  
- ğŸ§  Multimodal Dataset QA  
- ğŸ›¡ï¸ AI Safety, Alignment & Benchmarking
