# ğŸ‘¤ Laraib Ahmad Siddiqui

## ğŸ¤– AI Trainer | Agent Evaluation Specialist  
### ğŸ”¬ RLHF, Multimodal & Tool-Based Systems

ğŸ“ New Delhi, India  
ğŸ“§ [laraibdevops@gmail.com](mailto:laraibdevops@gmail.com)  
ğŸ“ +91-9540880891  

---

## ğŸ§  PROFESSIONAL SUMMARY

AI Trainer and Evaluation Specialist with extensive experience working on **large-scale language models, tool-using agents, coding agents, and multimodal AI systems**. Proven ability to deliver **high-fidelity training and evaluation data** used directly in production AI pipelines for enterprise clients including **Amazon, Google, Meta**, and leading AI research vendors through **Invisible Technologies, Outlier AI, Mindrift, and Rex.Zone**.

Expertise spans **Reinforcement Learning from Human Feedback (RLHF)**, **reward-model preference ranking**, **tool-agent trajectory evaluation (TAU)**, **multi-turn conversational alignment**, **code execution validation**, and **computer vision annotation & QA**. Known for identifying subtle hallucinations, policy violations, reasoning errors, and tool misuse that outcome-only metrics fail to capture.

---

## ğŸ§© CORE AREAS OF EXPERTISE

- ğŸ” Reinforcement Learning from Human Feedback (RLHF)
- ğŸ† Reward Model & Preference Ranking
- ğŸ§­ Toolâ€“Agentâ€“User (TAU) Evaluation Frameworks
- ğŸ’¬ Multi-Turn Conversation Evaluation
- ğŸ’» Coding Agent Evaluation & Repo-Based Testing
- âŒ Hallucination Detection & Factuality QA
- ğŸ“œ Policy-Constrained Agent Evaluation
- ğŸ‘ï¸ Computer Vision Annotation & QA
- ğŸ¥ Pose Estimation & Video Annotation
- ğŸ§  Multimodal Evaluation (Text, Image, Audio, Video)
- ğŸ“ Schema-Driven Annotation & Golden-Set Validation

---

## ğŸ¢ PROFESSIONAL EXPERIENCE

---

## ğŸ§ª Invisible Technologies  
**AI Trainer | LLM & Vision Evaluation Specialist**  
ğŸ“† *2023 â€“ Present*

Worked across multiple high-impact enterprise AI projects involving LLM alignment, code generation evaluation, multimodal vision QA, and large-scale dataset validation.

---

### ğŸŸ  Amazon Phoenix â€” RLHF Evaluation (3H Framework)

**Responsibilities**
- Evaluated model outputs for **Honesty, Helpfulness, Harmlessness**
- Flagged hallucinations, misleading claims, and safety risks
- Ranked responses with structured preference rationales
- Ensured alignment with user intent and policy constraints

**Impact**
- ğŸ“‰ Reduced hallucination frequency by **~40%**
- ğŸ›¡ï¸ Improved safety and reliability in production models

---

### ğŸ”µ Google Gemini â€” Coding, Factuality & Multi-Turn Evaluation

**Responsibilities**
- Executed AI-generated code for runtime validation
- Debugged logical and syntactic failures
- Audited multi-turn reasoning and factual grounding
- Identified instruction-following drift

**Impact**
- ğŸ“ˆ Improved code reliability by **~35%**
- ğŸ”„ Strengthened multi-turn reasoning consistency

---

### ğŸŸ£ Fika GenAI â€” RFI / RFP Coding Benchmarking

**Responsibilities**
- Benchmarked enterprise-grade AI coding outputs
- Assessed scalability, maintainability, and architecture
- Compared outputs for production readiness

**Impact**
- â±ï¸ Reduced decision cycles by **~25%**
- ğŸ—ï¸ Improved production suitability of shortlisted solutions

---

### ğŸŸ¢ Fornax Project â€” Pose Estimation & Dairy Farm Annotation QA

**Responsibilities**
- Verified pose keypoints, bounding boxes, occlusions, tubelets
- Ensured â‰¥32-frame continuity and temporal consistency
- Audited sensitive classes using strict annotation guides
- Coordinated with L2 QA and annotators via Slack

**Impact**
- ğŸ¯ Increased dataset precision by **~30%**
- ğŸ„ Improved motion tracking & behavior recognition accuracy

---

### ğŸŸ¦ Meta Big Downselect â€” Vision QA (Client: Meta)

**Responsibilities**
- Compared generated images against reference images
- Assessed anatomical correctness and artifact presence
- Verified identity preservation and visual plausibility
- Applied strict pass/fail and failure categorization

**Impact**
- ğŸ–¼ï¸ Improved vision dataset filtering by **~25%**
- ğŸš€ Strengthened generative image training datasets

---

## ğŸ§‘â€ğŸ”¬ Outlier AI  
**AI Trainer | RLHF Specialist**  
ğŸ“† *2024 â€“ Present*

---

### ğŸ“ Kepler â€” Mathematical Reasoning RLHF
- Evaluated step-by-step reasoning and derivations  
**Impact:** +40% reasoning accuracy

---

### ğŸ§ª Gallon Hamster â€” Short-Answer Prompt Generation
- Authored and QAâ€™d concise factual prompts  
**Impact:** +30% dataset quality

---

### ğŸ”Š Xylophone Grassland â€” Audio & Multimodal Evaluation
- Evaluated text-to-audio semantic alignment  
**Impact:** +25% multimodal consistency

---

### ğŸ§® Psychic Kadabra â€” SFT Math Prompt Alignment
- Authored instructional math prompts  
**Impact:** +35% clarity & reasoning structure

---

### âš–ï¸ Project P â€” Pairwise Side-by-Side Evaluation
- Conducted comparative evaluations with code execution  
**Impact:** +30% preference-model accuracy

---

## ğŸ§  Mindrift  
**AI Trainer | Agent, Conversation & Reward Model Evaluator**  
ğŸ“† *2024*

---

### ğŸ§­ TAU Evaluation â€” Agent Trajectory Analysis
- Reviewed tool-call sequences and state mutations
- Distinguished outcome correctness vs process correctness
- Classified faults (Agent / User / Technical)

**Impact**
- ğŸ“Š Improved agent benchmarking fidelity

---

### ğŸ” Food Delivery Agent â€” Policy-Constrained Domain
- Evaluated authentication, payments, refunds, tier rules
- Ensured policy-compliant tool usage under pressure

**Impact**
- ğŸ” Reduced silent policy violations

---

### ğŸ§‘â€ğŸ’» Project A â€” Virtual Company (Coding Agent Evaluation)
- Designed Jira-style repo tasks
- Validated code changes with tests and docs

**Impact**
- ğŸ­ Enabled production-like coding agent benchmarking

---

### ğŸ’¬ Interactive Preferences â€” Multi-Turn Conversations
- Generated 4â€“10 turn conversations
- Applied root-cause hierarchy for scoring

**Impact**
- ğŸ¯ Improved long-horizon conversational alignment

---

### ğŸ‘ Apricot â€” Preference Ranking
- Side-by-side reward model evaluation  
**Impact:** +30% reward-model reliability

---

## ğŸ¥ Rex.Zone (RemoExpert)  
**AI Data Annotator (Vision)**  
ğŸ“† *2024 â€“ Present*

- Annotated image/video datasets under strict schemas
- Performed frame-level labeling and QA

**Impact**
- ğŸ“¦ Delivered production-grade CV datasets

---

## ğŸ“Š OVERALL IMPACT

- âŒ Hallucinations reduced by **up to 40%**
- ğŸ§  Reasoning accuracy improved by **~40%**
- ğŸ’» Code correctness improved by **~35%**
- ğŸ‘ï¸ Vision dataset precision improved by **25â€“30%**
- ğŸš€ Delivered datasets for **Amazon, Google, Meta**

---

## ğŸ¯ POSITIONING

Best suited for roles involving:

- ğŸ¤– LLM & Agent Evaluation
- ğŸ” RLHF & Reward Model Design
- ğŸ§­ Tool-Using Agents & Reliability
- ğŸ§  Multimodal Dataset QA
- ğŸ›¡ï¸ AI Safety, Alignment & Benchmarking
